{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img src=\"http://vision.skills.network/logo-light.png\" width=\"400\" alt=\"CV Studio logo\"  />\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://keras.io/img/logo.png\">\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2> Image Classification with Convolution Neural Network (CNN) using  Keras and Tensorflow</h2>\n","<h3>Project: Final_project_stop_signs</h3>\n","<h3>Training Run: Train</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["A Convolutional Neural Network is a type of neural network that is used to train models using images.\n"]},{"cell_type":"markdown","metadata":{},"source":["<ul>\n","    <li>Table of Content\n","        <ul>\n","            <li>Download Images and Annotations</li>\n","            <li>Build the Model</li>\n","            <li>Train the Model</li>\n","            <li>Model Performance</li>\n","            <li>Report Results</li>\n","        </ul>\n","    </li>\n","    \n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Important Libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#if you get an error in your environment please uncomment to install neccessary packages\n","# !pip install imutils\n","# !pip install skillsnetwork\n","# !pip install tensorflow==1.15\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import set_random_seed\n","import os\n","from os import path\n","from datetime import datetime\n","import shutil\n","import random\n","from skillsnetwork import cvstudio"]},{"cell_type":"markdown","metadata":{},"source":["## Download Your Images and Annotations\n"]},{"cell_type":"markdown","metadata":{},"source":["Now let's download the images from CV Studio.\n","\n","If you have run this section before, you don't need to run it again. Feel free to jump to the <b>Build the Model</b> section.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the CV Studio Client\n","cvstudioClient = cvstudio.CVStudio()\n","\n","# Download All Images\n","cvstudioClient.downloadAll()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the annotations from CV Studio\n","annotations = cvstudioClient.get_annotations()\n","num_classes = len(annotations['labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Move files into folders\n","\n","def labeldir(label):\n","    return path.join(os.getcwd(), 'images', label)\n","\n","for label in annotations['labels']:\n","    if not path.exists(labeldir(label)):\n","        os.mkdir(labeldir(label))\n","\n","for key, value in annotations['annotations'].items():\n","    src = path.join(os.getcwd(), 'images', key)\n","    if path.exists(src):\n","        dest = (path.join(labeldir(value[0]['label']), key))\n","        shutil.move(src, dest)"]},{"cell_type":"markdown","metadata":{},"source":["## Build the Model\n","\n","We start with a MobileNetV2 architecture as the backbone pretrained feature extractor. We then add a couple of dense layers and a softmax layer to perfom the classification. We freeze the MobileNetV2 backbone with weights trained on ImageNet dataset and only train the dense layers and softmax layer that we have added.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_model=tf.keras.applications.MobileNetV2(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n","x=base_model.output\n","x=tf.keras.layers.GlobalAveragePooling2D()(x)\n","x=tf.keras.layers.Dense(512,activation='relu')(x) #dense layer 1\n","x=tf.keras.layers.Dense(256,activation='relu')(x) #dense layer 2\n","preds=tf.keras.layers.Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n","\n","model=tf.keras.Model(inputs=base_model.input,outputs=preds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Freeze layers from MobileNetV2 backbone (not to be trained)\n","for layer in base_model.layers:\n","    layer.trainable=False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Prepare the training dataset as a data generator object\n","train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input) #included in our dependencies\n","\n","train_generator=train_datagen.flow_from_directory('images',\n","                                                 target_size=(224,224),\n","                                                 color_mode='rgb',\n","                                                 batch_size=10,\n","                                                 class_mode='categorical',\n","                                                 shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model\n","model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Train the Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_datetime = datetime.now()\n","\n","set_random_seed(2)\n","step_size_train=5\n","epochs=4\n","log_file = model.fit_generator(generator=train_generator,\n","                   steps_per_epoch=step_size_train,\n","                   epochs=epochs)\n","\n","end_datetime = datetime.now()\n","print('Training Duration: ' + str(end_datetime-start_datetime))"]},{"cell_type":"markdown","metadata":{},"source":["## Model Performance\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model accuracy and loss vs epoch\n","plt.plot(log_file.history['acc'], '-bo', label=\"train_accuracy\")\n","plt.plot(log_file.history['loss'], '-r*', label=\"train_loss\")\n","plt.title('Training Loss and Accuracy')\n","plt.ylabel('Loss/Accuracy')\n","plt.xlabel('Epoch #')\n","plt.legend(loc='center right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Report Our Results Back to CV Studio\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["parameters = {\n","    'epochs': epochs\n","    'step_size_train': step_size_train,\n","    'class_indices': train_generator.class_indices\n","}\n","accuracy = {\n","    'accuracy': log_file.history['acc'],\n","    'loss': log_file.history['loss']\n","}\n","result = cvstudioClient.report(started=start_datetime, completed=end_datetime, parameters=parameters, accuracy=accuracy)\n","\n","if result.ok:\n","    print('Congratulations your results have been reported back to CV Studio!')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the model to a file\n","model.save('my_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["parameters = {\n","    'epochs': epochs\n","    'step_size_train': step_size_train,\n","    \n","}\n","# Now let's save the model back to CV Studio\n","result = cvstudioClient.uploadModel('my_model.h5', parameters)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Thanks for completing this notebook!\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"}},"nbformat":4,"nbformat_minor":4}